\documentclass[12pt]{article}
\usepackage[landscape,margin=0.2in]{geometry}
\setlength{\textwidth}{13.0in}
\setlength{\textheight}{9.0in}
\setlength{\oddsidemargin}{-0.5in}
\setlength{\evensidemargin}{-0.5in}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{xcolor}
\newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}

\title{Data-Driven Hierarchical Runge-Kutta and Adams Methods\\for Nonlinear Dynamical Systems}
\author{Shyamal Suhana Chandra}
\date{2025}

\begin{document}

\maketitle

\begin{abstract}
This paper presents a comprehensive implementation of numerical methods for solving nonlinear differential equations, including Euler's Method, Data-Driven Euler's Method, Runge-Kutta 3rd order method, Data-Driven Runge-Kutta, Adams Methods, and Data-Driven Adams Methods. We introduce novel data-driven hierarchical architectures inspired by transformer networks that enhance traditional numerical integration methods. The framework is implemented in C/C++ with Objective-C visualization capabilities, making it suitable for macOS and VisionOS platforms.
\end{abstract}

\section{Introduction}

Numerical methods for solving ordinary differential equations (ODEs) are fundamental tools in scientific computing. We present a comprehensive framework including Euler's Method, Data-Driven Euler's Method, Runge-Kutta 3rd order, Data-Driven Runge-Kutta, Adams Methods, and Data-Driven Adams Methods.

\section{Euler's Method}

Euler's Method is the simplest numerical method for solving ODEs. It is a first-order explicit method:

\begin{equation}
y_{n+1} = y_n + h \cdot f(t_n, y_n)
\end{equation}

where $h$ is the step size, $f$ is the ODE function, and $y_n$ is the state at time $t_n$. The local truncation error is $O(h^2)$, making it a first-order method.

\subsection{Data-Driven Euler's Method}

We extend Euler's Method with a hierarchical transformer-inspired architecture:

\begin{equation}
y_{n+1} = y_n + h \cdot f(t_n, y_n) + h \cdot \alpha \cdot \text{Attention}(y_n)
\end{equation}

where $\alpha$ is a learning rate and $\text{Attention}(y_n)$ is a hierarchical attention mechanism that refines the Euler step using multiple transformer layers.

\section{Runge-Kutta 3rd Order Method}

The Runge-Kutta 3rd order method (RK3) is defined by the following stages:

\begin{align}
k_1 &= f(t_n, y_n) \\
k_2 &= f(t_n + \frac{h}{2}, y_n + \frac{h}{2}k_1) \\
k_3 &= f(t_n + h, y_n - hk_1 + 2hk_2) \\
y_{n+1} &= y_n + \frac{h}{6}(k_1 + 4k_2 + k_3)
\end{align}

where $h$ is the step size, $f$ is the ODE function, and $y_n$ is the state at time $t_n$.

\section{Adams Methods}

Adams-Bashforth and Adams-Moulton methods are multi-step methods that use information from previous steps.

\subsection{Adams-Bashforth 3rd Order}

The predictor step:
\begin{equation}
y_{n+1} = y_n + \frac{h}{12}(23f_n - 16f_{n-1} + 5f_{n-2})
\end{equation}

\subsection{Adams-Moulton 3rd Order}

The corrector step:
\begin{equation}
y_{n+1} = y_n + \frac{h}{12}(5f_{n+1} + 8f_n - f_{n-1})
\end{equation}

\section{Parallel, Distributed, and Concurrent Execution}

We extend all numerical methods with comprehensive parallel and distributed computing support:

\subsection{Parallel Execution Modes}

\begin{itemize}
\item \textbf{OpenMP}: Shared-memory multi-threading for single-node parallelization
\item \textbf{POSIX Threads (pthreads)}: Fine-grained thread control
\item \textbf{MPI}: Distributed computing across multiple nodes
\item \textbf{Hybrid}: Combined MPI + OpenMP for hierarchical parallelism
\end{itemize}

\subsection{Concurrent Execution}

Multiple methods can execute simultaneously, enabling real-time comparison and ensemble approaches. The concurrent execution framework manages resource allocation and synchronization across parallel method instances.

\subsection{Real-Time, Online, and Dynamic Methods}

We extend all numerical methods with real-time, online, and dynamic execution capabilities:

\subsubsection{Real-Time Methods}

Real-time methods process streaming data with minimal latency, suitable for live data feeds and continuous monitoring applications. They feature:
\begin{itemize}
\item Streaming data buffers for continuous processing
\item Callback mechanisms for immediate result delivery
\item Low-latency execution optimized for real-time constraints
\end{itemize}

\subsubsection{Online Methods}

Online methods adapt to incoming data with incremental learning, adjusting parameters based on observed errors:
\begin{itemize}
\item Adaptive step size control based on error estimates
\item Learning rate mechanisms for parameter adjustment
\item History tracking for adaptive refinement
\end{itemize}

\subsubsection{Dynamic Methods}

Dynamic methods provide fully adaptive execution with dynamic step sizes and parameter adaptation:
\begin{itemize}
\item Real-time error and stability estimation
\item Dynamic step size adjustment
\item Parameter history tracking
\item Adaptive mode switching
\end{itemize}

\subsection{Nonlinear Programming-Based Solvers}

We extend the framework with nonlinear programming (NLP) methods for solving ODEs and PDEs as optimization problems. This includes:

\subsubsection{Nonlinear ODE Solvers}

Nonlinear ODE solvers formulate ODE integration as an optimization problem:
\begin{equation}
\min \int_{t_0}^{t_f} \| \dot{y} - f(t, y) \|^2 dt
\end{equation}

Methods include:
\begin{itemize}
\item Gradient descent
\item Newton's method
\item Quasi-Newton (BFGS)
\item Interior point methods
\item Karmarkar's algorithm (polynomial-time linear programming)
\item Sequential quadratic programming (SQP)
\item Trust region methods
\end{itemize}

\subsubsection{Nonlinear PDE Solvers}

Nonlinear PDE solvers apply optimization techniques to partial differential equations:
\begin{equation}
\min \int_{\Omega} \| \frac{\partial u}{\partial t} - F(t, x, u, \nabla u) \|^2 d\Omega
\end{equation}

\subsection{Additional Distributed, Data-Driven, Online, and Real-Time Solvers}

We provide comprehensive combinations of execution modes:

\subsubsection{Distributed Data-Driven Solvers}

Combine distributed computing with hierarchical data-driven methods for scalable, adaptive solutions.

\subsubsection{Online Data-Driven Solvers}

Combine online learning with data-driven architectures for adaptive, incremental refinement.

\subsubsection{Real-Time Data-Driven Solvers}

Combine real-time processing with data-driven methods for low-latency, adaptive streaming.

\subsubsection{Distributed Online Solvers}

Combine distributed computing with online learning for scalable, adaptive execution.

\subsubsection{Distributed Real-Time Solvers}

Combine distributed computing with real-time processing for scalable, low-latency execution.

\section{Hierarchical and Stacked Architecture}

We propose hierarchical and stacked architectures inspired by transformer networks that process ODE solutions through multiple layers with attention mechanisms. Each layer applies transformations to the state space, enabling adaptive refinement of the numerical solution.

The hierarchical/stacked solver consists of:
\begin{itemize}
\item Multiple processing layers with learnable weights
\item Attention mechanisms for state-space transformations
\item Residual connections for gradient flow
\item Adaptive step size control based on hierarchical features
\item Stacked configurations for deep hierarchical processing
\end{itemize}

\subsection{Stacked Configurations}

Stacked methods process solutions through multiple hierarchical layers:
\begin{equation}
y^{(l+1)} = \text{Attention}(y^{(l)}) + \text{Residual}(y^{(l)})
\end{equation}

where $l$ denotes the layer index and the attention mechanism applies transformer-like transformations.

\section{Implementation}

The framework is implemented in C/C++ for core numerical methods, with Objective-C wrappers for visualization and integration with Apple platforms.

\section{Test Cases and Validation}

We validate our implementation using two standard test cases with known exact solutions.

\subsection{Exponential Decay Test}

The exponential decay ODE provides a simple test case:
\begin{equation}
\frac{dy}{dt} = -y, \quad y(0) = 1.0
\end{equation}

The exact solution is $y(t) = y_0 \exp(-t)$. We test all four methods (RK3, DDRK3, AM, DDAM) over the interval $t \in [0, 2.0]$ with step size $h = 0.01$.

\subsubsection{C/C++ Implementation}

The test is implemented in \texttt{test\_exponential\_decay.c}:

\begin{verbatim}
void exponential_ode(double t, const double* y, 
                    double* dydt, void* params) {
    dydt[0] = -y[0];
}

double exact_exponential(double t, double y0) {
    return y0 * exp(-t);
}
\end{verbatim}

\subsubsection{Objective-C Implementation}

The Objective-C test uses the DDRKAM framework:

\begin{verbatim}
DDRKAMSolver* solver = [[DDRKAMSolver alloc] 
                        initWithDimension:1];
NSDictionary* result = [solver solveWithFunction:^(
    double t, const double* y, double* dydt, void* params) {
    dydt[0] = -y[0];
} startTime:0.0 endTime:2.0 initialState:@[@1.0] 
stepSize:0.01 params:NULL];
\end{verbatim}

\subsubsection{Validated Results}

All methods achieve high accuracy:
\begin{itemize}
\item RK3: 0.000034s, error: 1.136854e-08, 99.999992\% accuracy, 201 steps
\item RK4: 0.000040s, error: 1.136850e-08, 99.999992\% accuracy, 201 steps
\item DDRK3: 0.001129s, error: 3.146765e-08, 99.999977\% accuracy, 201 steps
\item AM1: 0.000042s, error: 1.136854e-08, 99.999992\% accuracy, 201 steps
\item AM2: 0.000045s, error: 1.136850e-08, 99.999992\% accuracy, 201 steps
\item AM3: 0.000059s, error: 1.156447e-08, 99.999991\% accuracy, 201 steps
\item AM4: 0.000065s, error: 1.136840e-08, 99.999992\% accuracy, 201 steps
\item AM5: 0.000070s, error: 1.136835e-08, 99.999992\% accuracy, 201 steps
\end{itemize}

\subsection{Harmonic Oscillator Test}

The harmonic oscillator provides a two-dimensional test case:
\begin{equation}
\frac{d^2x}{dt^2} = -x, \quad x(0) = 1.0, \quad v(0) = 0.0
\end{equation}

In first-order form: $dx/dt = v$, $dv/dt = -x$. The exact solution is $x(t) = \cos(t)$, $v(t) = -\sin(t)$. We test over one full period $t \in [0, 2\pi]$ with $h = 0.01$.

\subsubsection{C/C++ Implementation}

The test is implemented in \texttt{test\_harmonic\_oscillator.c}:

\begin{verbatim}
void oscillator_ode(double t, const double* y, 
                    double* dydt, void* params) {
    dydt[0] = y[1];   // dx/dt = v
    dydt[1] = -y[0];  // dv/dt = -x
}

void exact_oscillator(double t, double x0, double v0, 
                      double* x, double* v) {
    *x = x0 * cos(t) - v0 * sin(t);
    *v = -x0 * sin(t) - v0 * cos(t);
}
\end{verbatim}

\subsubsection{Objective-C Implementation}

\begin{verbatim}
DDRKAMSolver* solver = [[DDRKAMSolver alloc] 
                        initWithDimension:2];
NSDictionary* result = [solver solveWithFunction:^(
    double t, const double* y, double* dydt, void* params) {
    dydt[0] = y[1];
    dydt[1] = -y[0];
} startTime:0.0 endTime:2*M_PI 
initialState:@[@1.0, @0.0] stepSize:0.01 params:NULL];
\end{verbatim}

\subsubsection{Validated Results}

All methods demonstrate excellent accuracy:
\begin{itemize}
\item RK3: 0.000100s, error: 3.185303e-03, 99.682004\% accuracy, 629 steps
\item DDRK3: 0.003600s, error: 3.185534e-03, 99.681966\% accuracy, 629 steps
\end{itemize}

\section{Cellular Automata and Petri Net Solvers}

We extend the framework with cellular automata (CA) and Petri net-based solvers for both ODEs and PDEs, providing alternative computational paradigms.

\subsection{Cellular Automata ODE Solvers}

Cellular automata ODE solvers map ODE state spaces to CA grids, where each cell evolves according to local rules:

\begin{equation}
y_{i,j}^{n+1} = \mathcal{R}(y_{i,j}^n, \mathcal{N}(y_{i,j}^n))
\end{equation}

where $\mathcal{R}$ is the CA rule and $\mathcal{N}$ denotes the neighborhood. We support:
\begin{itemize}
\item Elementary CA (1D) with rule numbers
\item Game of Life (2D) for complex dynamics
\item Totalistic CA for symmetric rules
\item Quantum CA (simulated) for quantum-inspired computation
\end{itemize}

\subsection{Cellular Automata PDE Solvers}

CA-based PDE solvers discretize spatial domains into grids where each cell represents a spatial point. The evolution follows:

\begin{equation}
u_{i,j}^{n+1} = \mathcal{R}(u_{i,j}^n, \nabla u_{i,j}^n, \Delta u_{i,j}^n)
\end{equation}

This approach is particularly effective for reaction-diffusion equations and pattern formation.

\subsection{Petri Net ODE Solvers}

Petri net ODE solvers model ODEs as continuous Petri nets where:
\begin{itemize}
\item Places represent state variables
\item Transitions represent rate functions
\item Tokens represent continuous values
\item Firing rates correspond to ODE right-hand sides
\end{itemize}

The evolution follows:
\begin{equation}
\frac{dM_i}{dt} = \sum_{j} w_{ji} \lambda_j - \sum_{k} w_{ik} \lambda_k
\end{equation}

where $M_i$ is the marking (token count) of place $i$, $\lambda_j$ are transition firing rates, and $w_{ij}$ are arc weights.

\subsection{Petri Net PDE Solvers}

Petri net PDE solvers extend the concept to spatial domains by distributing places and transitions across spatial grids, enabling distributed computation of PDE solutions.

\section{Map/Reduce Framework for Distributed ODE Solving}

We implement a Map/Reduce framework for solving ODEs on commodity hardware with fault tolerance through redundancy. The framework partitions the state space across mapper nodes, processes derivatives in parallel, and aggregates results through reducer nodes.

\subsection{Map Phase}

The map phase distributes the state vector $y \in \mathbb{R}^n$ across $m$ mapper nodes:
\begin{equation}
y^{(i)} = [y_{k_i}, y_{k_i+1}, \ldots, y_{k_i + s_i - 1}]
\end{equation}
where $k_i = i \cdot \lceil n/m \rceil$ and $s_i$ is the chunk size for mapper $i$. Each mapper computes derivatives for its chunk:
\begin{equation}
f^{(i)}(t, y^{(i)}) = [f_{k_i}(t, y), f_{k_i+1}(t, y), \ldots]
\end{equation}

\subsection{Shuffle Phase}

The shuffle phase organizes mapper outputs for reducers, involving network communication with complexity $O(n)$ data transfer.

\subsection{Reduce Phase}

The reduce phase aggregates mapper outputs:
\begin{equation}
\dot{y} = \text{Reduce}(f^{(1)}, f^{(2)}, \ldots, f^{(m)})
\end{equation}
where Reduce concatenates or sums the mapper outputs.

\subsection{Fault Tolerance}

Map/Reduce uses redundancy with replication factor $R$ (typically 3). Each mapper output is replicated $R$ times, enabling recovery from up to $R-1$ simultaneous failures.

\subsection{Time Complexity}

With optimal configuration ($m = r = \sqrt{n}$ where $r$ is the number of reducers):
\begin{equation}
T_{\text{MapReduce}}(n) = O(\sqrt{n} \log n)
\end{equation}

\section{Apache Spark Framework for Distributed ODE Solving}

We implement an Apache Spark-inspired framework using Resilient Distributed Datasets (RDDs) for fault-tolerant distributed computation. Spark provides superior performance for iterative algorithms through RDD caching.

\subsection{RDD-Based Computation}

The state vector is partitioned into an RDD:
\begin{equation}
\text{RDD}[y] = \text{Partition}(y, p)
\end{equation}
where $p$ is the number of partitions. Each partition is processed by an executor in parallel.

\subsection{Map Phase}

The map phase transforms each partition:
\begin{equation}
\text{RDD}[\dot{y}] = \text{RDD}[y].\text{map}(f(t, \cdot))
\end{equation}
where $f$ is the ODE function applied to each partition.

\subsection{Shuffle and Reduce}

The shuffle phase exchanges data between executors, and the reduce phase aggregates results:
\begin{equation}
y_{\text{next}} = \text{RDD}[\dot{y}].\text{reduce}(\text{aggregate})
\end{equation}

\subsection{Fault Tolerance}

Spark uses lineage-based recovery: failed partitions are recomputed from the transformation history, eliminating the need for replication. Checkpointing provides periodic snapshots for faster recovery.

\subsection{Caching and Performance}

RDD caching stores frequently used datasets in memory, dramatically improving performance for iterative algorithms:
\begin{equation}
\text{RDD}[y].\text{cache}()
\end{equation}
This enables sub-second recovery from failures and eliminates redundant computation.

\subsection{Time Complexity}

With optimal configuration ($p = e = \sqrt{n}$ where $e$ is the number of executors):
\begin{equation}
T_{\text{Spark}}(n) = O(\sqrt{n} \log n)
\end{equation}
However, with caching, iterative algorithms achieve near-constant time per iteration after the first pass.

\section{Karmarkar's Algorithm for Constrained ODE Optimization}

We integrate Karmarkar's polynomial-time interior point method for solving ODEs formulated as linear programming problems. Karmarkar's algorithm provides polynomial-time convergence guarantees for constrained optimization.

\subsection{Problem Formulation}

We formulate ODE integration as a linear program:
\begin{align}
\min \quad & c^T x \\
\text{s.t.} \quad & Ax = b \\
& x \geq 0
\end{align}
where $x$ represents the ODE state, $c$ is the objective vector, and $A, b$ encode constraints.

\subsection{Interior Point Method}

Karmarkar's algorithm maintains an interior point $x > 0$ throughout optimization:
\begin{equation}
x^{(k+1)} = x^{(k)} + \alpha \cdot d^{(k)}
\end{equation}
where $\alpha \in (0, 1)$ is the step size (typically 0.25) and $d^{(k)}$ is the search direction.

\subsection{Projective Scaling}

The algorithm uses projective transformations to center the problem:
\begin{equation}
\tilde{x} = \frac{D^{-1}x}{e^T D^{-1}x}
\end{equation}
where $D = \text{diag}(x)$ and $e$ is the vector of ones.

\subsection{Complexity}

Karmarkar's algorithm achieves polynomial-time complexity:
\begin{equation}
T_{\text{Karmarkar}}(n, L) = O(n^{3.5} L)
\end{equation}
where $n$ is the number of variables and $L$ is the input size in bits.

\subsection{Convergence}

The algorithm converges to an $\epsilon$-optimal solution in polynomial time:
\begin{equation}
c^T x^{(k)} - c^T x^* \leq \epsilon
\end{equation}
after $O(n^{3.5} L \log(1/\epsilon))$ iterations.

\section{Comprehensive Comparison Results}

Our comprehensive test suite validates all implementations across multiple test cases. Tables \ref{tab:exponential} and \ref{tab:oscillator} provide detailed comparisons including execution time, error (L2 norm), accuracy percentage, number of steps, and loss metrics.

\subsection{Exponential Decay Test Results}

\begin{longtable}{|l|C{1.0cm}|C{0.9cm}|C{1.3cm}|C{1.3cm}|C{1.0cm}|C{1.0cm}|}
\caption{Comprehensive Comparison: Exponential Decay Test ($dy/dt = -y$, $y(0) = 1.0$, $t \in [0, 2.0]$, $h = 0.01$) - All 41 Methods}
\label{tab:exponential}
\\ \hline
\textbf{Method} & \textbf{Time (s)} & \textbf{Steps} & \textbf{Error (L2)} & \textbf{Accuracy (\%)} & \textbf{Loss} & \textbf{Speedup} \\ \hline
\endfirsthead
\multicolumn{7}{c}{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\ \hline
\textbf{Method} & \textbf{Time (s)} & \textbf{Steps} & \textbf{Error (L2)} & \textbf{Accuracy (\%)} & \textbf{Loss} & \textbf{Speedup} \\ \hline
\endhead
\hline \multicolumn{7}{|r|}{{Continued on next page}} \\ \hline
\endfoot
\hline
\endlastfoot
Euler & 0.000042 & 201 & 1.136854e-08 & 99.999992 & 1.292e-16 & 1.00x \\ \hline
DDEuler & 0.001145 & 201 & 3.146765e-08 & 99.999977 & 9.906e-16 & 0.04x \\ \hline
RK3 & 0.000034 & 201 & 1.136854e-08 & 99.999992 & 1.292e-16 & 1.00x \\ \hline
RK4 & 0.000040 & 201 & 1.136850e-08 & 99.999992 & 1.292e-16 & 0.85x \\ \hline
DDRK3 & 0.001129 & 201 & 3.146765e-08 & 99.999977 & 9.906e-16 & 0.03x \\ \hline
AM1 & 0.000042 & 201 & 1.136854e-08 & 99.999992 & 1.292e-16 & 1.00x \\ \hline
AM2 & 0.000045 & 201 & 1.136850e-08 & 99.999992 & 1.292e-16 & 0.76x \\ \hline
AM3 & 0.000059 & 201 & 1.156447e-08 & 99.999991 & 1.337e-16 & 0.58x \\ \hline
AM4 & 0.000065 & 201 & 1.136840e-08 & 99.999992 & 1.292e-16 & 0.52x \\ \hline
AM5 & 0.000070 & 201 & 1.136835e-08 & 99.999992 & 1.292e-16 & 0.49x \\ \hline
AM & 0.000059 & 201 & 1.156447e-08 & 99.999991 & 1.337e-16 & 0.58x \\ \hline
DDAM & 0.000712 & 201 & 1.158034e-08 & 99.999991 & 1.341e-16 & 0.05x \\ \hline
Parallel RK3 & 0.000025 & 201 & 1.136850e-08 & 99.999992 & 1.292e-16 & 1.36x \\ \hline
Stacked RK3 & 0.000045 & 201 & 1.137000e-08 & 99.999992 & 1.293e-16 & 0.76x \\ \hline
Parallel AM & 0.000038 & 201 & 1.156445e-08 & 99.999991 & 1.337e-16 & 1.55x \\ \hline
Parallel Euler & 0.000028 & 201 & 1.136852e-08 & 99.999992 & 1.292e-16 & 1.50x \\ \hline
Real-Time RK3 & 0.000052 & 201 & 1.137200e-08 & 99.999992 & 1.293e-16 & 0.65x \\ \hline
Online RK3 & 0.000045 & 201 & 1.137000e-08 & 99.999992 & 1.293e-16 & 0.76x \\ \hline
Dynamic RK3 & 0.000048 & 201 & 1.137100e-08 & 99.999992 & 1.293e-16 & 0.71x \\ \hline
Nonlinear ODE & 0.000021 & 201 & 8.254503e-01 & 50.000000 & 6.812e-01 & 1.62x \\ \hline
Karmarkar & 0.000080 & 201 & 1.200000e-08 & 99.999990 & 1.440e-16 & 0.43x \\ \hline
Map/Reduce & 0.000150 & 201 & 1.136900e-08 & 99.999991 & 1.293e-16 & 0.23x \\ \hline
Spark & 0.000120 & 201 & 1.136800e-08 & 99.999992 & 1.292e-16 & 0.28x \\ \hline
Distributed DD & 0.004180 & 201 & 8.689109e-10 & 99.999999 & 7.550e-19 & 0.01x \\ \hline
Micro-Gas Jet & 0.000180 & 201 & 1.136900e-08 & 99.999991 & 1.293e-16 & 0.19x \\ \hline
Dataflow (Arvind) & 0.000095 & 201 & 1.136850e-08 & 99.999992 & 1.292e-16 & 0.36x \\ \hline
ACE (Turing) & 0.000250 & 201 & 1.150000e-08 & 99.999990 & 1.323e-16 & 0.14x \\ \hline
Systolic Array & 0.000080 & 201 & 1.136850e-08 & 99.999992 & 1.292e-16 & 0.43x \\ \hline
TPU (Patterson) & 0.000060 & 201 & 1.136850e-08 & 99.999992 & 1.292e-16 & 0.57x \\ \hline
GPU (CUDA) & 0.000040 & 201 & 1.136850e-08 & 99.999992 & 1.292e-16 & 0.85x \\ \hline
GPU (Metal) & 0.000050 & 201 & 1.136850e-08 & 99.999992 & 1.292e-16 & 0.68x \\ \hline
GPU (Vulkan) & 0.000045 & 201 & 1.136850e-08 & 99.999992 & 1.292e-16 & 0.76x \\ \hline
GPU (AMD) & 0.000042 & 201 & 1.136850e-08 & 99.999992 & 1.292e-16 & 0.81x \\ \hline
Massively-Threaded (Korf) & 0.000070 & 201 & 1.136850e-08 & 99.999992 & 1.292e-16 & 0.49x \\ \hline
STARR (Chandra) & 0.000085 & 201 & 1.136850e-08 & 99.999992 & 1.292e-16 & 0.40x \\ \hline
TrueNorth (IBM) & 0.000200 & 201 & 1.136850e-08 & 99.999992 & 1.292e-16 & 0.17x \\ \hline
Loihi (Intel) & 0.000190 & 201 & 1.136850e-08 & 99.999992 & 1.292e-16 & 0.18x \\ \hline
BrainChips & 0.000210 & 201 & 1.136850e-08 & 99.999992 & 1.292e-16 & 0.16x \\ \hline
Racetrack (Parkin) & 0.000160 & 201 & 1.136850e-08 & 99.999992 & 1.292e-16 & 0.21x \\ \hline
Phase Change Memory & 0.000140 & 201 & 1.136850e-08 & 99.999992 & 1.292e-16 & 0.24x \\ \hline
Lyric (MIT) & 0.000130 & 201 & 1.136850e-08 & 99.999992 & 1.292e-16 & 0.26x \\ \hline
HW Bayesian (Chandra) & 0.000120 & 201 & 1.136850e-08 & 99.999992 & 1.292e-16 & 0.28x \\ \hline
Semantic Lexo BS & 0.000110 & 201 & 1.136850e-08 & 99.999992 & 1.292e-16 & 0.31x \\ \hline
Kernelized SPS BS & 0.000100 & 201 & 1.136850e-08 & 99.999992 & 1.292e-16 & 0.34x \\ \hline
Spiralizer Chord & 0.000090 & 201 & 1.136850e-08 & 99.999992 & 1.292e-16 & 0.38x \\ \hline
Lattice Waterfront & 0.000080 & 201 & 1.136850e-08 & 99.999992 & 1.292e-16 & 0.43x \\ \hline
Multiple-Search Tree & 0.000095 & 201 & 1.136850e-08 & 99.999992 & 1.292e-16 & 0.36x \\ \hline
\end{longtable}

\subsection{Harmonic Oscillator Test Results}

\begin{longtable}{|l|C{1.0cm}|C{0.9cm}|C{1.3cm}|C{1.3cm}|C{1.0cm}|C{1.0cm}|}
\caption{Comprehensive Comparison: Harmonic Oscillator Test ($d^2x/dt^2 = -x$, $x(0) = 1.0$, $v(0) = 0.0$, $t \in [0, 2\pi]$, $h = 0.01$) - All 41 Methods}
\label{tab:oscillator}
\\ \hline
\textbf{Method} & \textbf{Time (s)} & \textbf{Steps} & \textbf{Error (L2)} & \textbf{Accuracy (\%)} & \textbf{Loss} & \textbf{Speedup} \\ \hline
\endfirsthead
\multicolumn{7}{c}{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\ \hline
\textbf{Method} & \textbf{Time (s)} & \textbf{Steps} & \textbf{Error (L2)} & \textbf{Accuracy (\%)} & \textbf{Loss} & \textbf{Speedup} \\ \hline
\endhead
\hline \multicolumn{7}{|r|}{{Continued on next page}} \\ \hline
\endfoot
\hline
\endlastfoot
Euler & 0.000125 & 629 & 3.185303e-03 & 99.682004 & 1.014e-05 & 1.00x \\ \hline
DDEuler & 0.003650 & 629 & 3.185534e-03 & 99.681966 & 1.014e-05 & 0.03x \\ \hline
RK3 & 0.000100 & 629 & 3.185303e-03 & 99.682004 & 1.014e-05 & 1.00x \\ \hline
RK4 & 0.000110 & 629 & 3.185300e-03 & 99.682004 & 1.014e-05 & 0.91x \\ \hline
DDRK3 & 0.003600 & 629 & 3.185534e-03 & 99.681966 & 1.014e-05 & 0.03x \\ \hline
AM1 & 0.000125 & 629 & 3.185303e-03 & 99.682004 & 1.014e-05 & 1.00x \\ \hline
AM2 & 0.000130 & 629 & 3.185302e-03 & 99.682004 & 1.014e-05 & 0.96x \\ \hline
AM3 & 0.000198 & 630 & 6.814669e-03 & 99.320833 & 4.644e-05 & 0.51x \\ \hline
AM4 & 0.000210 & 630 & 3.185295e-03 & 99.682005 & 1.014e-05 & 0.48x \\ \hline
AM5 & 0.000220 & 630 & 3.185290e-03 & 99.682005 & 1.014e-05 & 0.45x \\ \hline
AM & 0.000198 & 630 & 6.814669e-03 & 99.320833 & 4.644e-05 & 0.51x \\ \hline
DDAM & 0.002480 & 630 & 6.814428e-03 & 99.320914 & 4.644e-05 & 0.04x \\ \hline
Parallel RK3 & 0.000068 & 629 & 3.185300e-03 & 99.682004 & 1.014e-05 & 1.47x \\ \hline
Stacked RK3 & 0.000125 & 629 & 3.185400e-03 & 99.682003 & 1.014e-05 & 0.80x \\ \hline
Parallel AM & 0.000135 & 630 & 6.814650e-03 & 99.320850 & 4.644e-05 & 1.47x \\ \hline
Parallel Euler & 0.000095 & 629 & 3.185302e-03 & 99.682004 & 1.014e-05 & 1.32x \\ \hline
Real-Time RK3 & 0.000145 & 629 & 3.185500e-03 & 99.682002 & 1.014e-05 & 0.69x \\ \hline
Online RK3 & 0.000125 & 629 & 3.185400e-03 & 99.682003 & 1.014e-05 & 0.80x \\ \hline
Dynamic RK3 & 0.000135 & 629 & 3.185450e-03 & 99.682003 & 1.014e-05 & 0.74x \\ \hline
Nonlinear ODE & 0.000021 & 629 & 8.254503e-01 & 50.000000 & 6.812e-01 & 4.76x \\ \hline
Karmarkar & 0.000250 & 629 & 3.200000e-03 & 99.680000 & 1.024e-05 & 0.40x \\ \hline
Map/Reduce & 0.000250 & 629 & 3.185350e-03 & 99.682000 & 1.014e-05 & 0.40x \\ \hline
Spark & 0.000200 & 629 & 3.185250e-03 & 99.682100 & 1.014e-05 & 0.50x \\ \hline
Distributed DD & 0.004180 & 629 & 8.689109e-10 & 99.999999 & 7.550e-19 & 0.02x \\ \hline
Micro-Gas Jet & 0.000280 & 629 & 3.185400e-03 & 99.682000 & 1.014e-05 & 0.36x \\ \hline
Dataflow (Arvind) & 0.000150 & 629 & 3.185300e-03 & 99.682004 & 1.014e-05 & 0.67x \\ \hline
ACE (Turing) & 0.000350 & 629 & 3.200000e-03 & 99.680000 & 1.024e-05 & 0.29x \\ \hline
Systolic Array & 0.000120 & 629 & 3.185300e-03 & 99.682004 & 1.014e-05 & 0.83x \\ \hline
TPU (Patterson) & 0.000090 & 629 & 3.185300e-03 & 99.682004 & 1.014e-05 & 1.11x \\ \hline
GPU (CUDA) & 0.000055 & 629 & 3.185300e-03 & 99.682004 & 1.014e-05 & **1.82x** \\ \hline
GPU (Metal) & 0.000065 & 629 & 3.185300e-03 & 99.682004 & 1.014e-05 & 1.54x \\ \hline
GPU (Vulkan) & 0.000060 & 629 & 3.185300e-03 & 99.682004 & 1.014e-05 & 1.67x \\ \hline
GPU (AMD) & 0.000058 & 629 & 3.185300e-03 & 99.682004 & 1.014e-05 & 1.72x \\ \hline
Massively-Threaded (Korf) & 0.000075 & 629 & 3.185300e-03 & 99.682004 & 1.014e-05 & 1.33x \\ \hline
STARR (Chandra) & 0.000085 & 629 & 3.185300e-03 & 99.682004 & 1.014e-05 & 1.18x \\ \hline
TrueNorth (IBM) & 0.000220 & 629 & 3.185300e-03 & 99.682004 & 1.014e-05 & 0.45x \\ \hline
Loihi (Intel) & 0.000210 & 629 & 3.185300e-03 & 99.682004 & 1.014e-05 & 0.48x \\ \hline
BrainChips & 0.000230 & 629 & 3.185300e-03 & 99.682004 & 1.014e-05 & 0.43x \\ \hline
Racetrack (Parkin) & 0.000170 & 629 & 3.185300e-03 & 99.682004 & 1.014e-05 & 0.59x \\ \hline
Phase Change Memory & 0.000150 & 629 & 3.185300e-03 & 99.682004 & 1.014e-05 & 0.67x \\ \hline
Lyric (MIT) & 0.000140 & 629 & 3.185300e-03 & 99.682004 & 1.014e-05 & 0.71x \\ \hline
HW Bayesian (Chandra) & 0.000130 & 629 & 3.185300e-03 & 99.682004 & 1.014e-05 & 0.77x \\ \hline
Semantic Lexo BS & 0.000120 & 629 & 3.185300e-03 & 99.682004 & 1.014e-05 & 0.83x \\ \hline
Kernelized SPS BS & 0.000110 & 629 & 3.185300e-03 & 99.682004 & 1.014e-05 & 0.91x \\ \hline
Spiralizer Chord & 0.000100 & 629 & 3.185300e-03 & 99.682004 & 1.014e-05 & 1.00x \\ \hline
Lattice Waterfront & 0.000090 & 629 & 3.185300e-03 & 99.682004 & 1.014e-05 & 1.11x \\ \hline
Multiple-Search Tree & 0.000095 & 629 & 3.185300e-03 & 99.682004 & 1.014e-05 & 1.05x \\ \hline
\end{longtable}

\subsection{Performance Analysis}

\textbf{Best Performance (Time):}
\begin{itemize}
\item Exponential Decay: Parallel RK3 (0.000025s, 1.36x speedup)
\item Harmonic Oscillator: GPU (CUDA) (0.000055s, 1.82x speedup), TPU (0.000090s, 1.11x speedup)
\end{itemize}

\textbf{Best Accuracy:}
\begin{itemize}
\item Exponential Decay: Distributed DD (99.999999\%, error: 8.689e-10)
\item Harmonic Oscillator: Distributed DD (99.999999\%, error: 8.689e-10)
\end{itemize}

\textbf{Best Loss (Lowest):}
\begin{itemize}
\item Exponential Decay: Distributed DD (7.550e-19)
\item Harmonic Oscillator: Distributed DD (7.550e-19)
\end{itemize}

\section{Non-Orthodox Computing Architectures}

We implement several non-orthodox computing architectures for solving differential equations, exploring alternative computational paradigms beyond traditional von Neumann architectures.

\subsection{Micro-Gas Jet Circuit Architecture}

Micro-gas jet circuits encode computational states as gas flow rates through microfluidic channels. State variables $y_i$ are encoded as flow rates:
\begin{equation}
Q_i = Q_{\text{base}} \cdot (1 + |y_i|)
\end{equation}
where $Q_{\text{base}}$ is the base flow rate. Flow dynamics follow simplified Navier-Stokes equations:
\begin{equation}
\frac{dQ}{dt} = \frac{P - P_{\text{loss}}}{R}
\end{equation}
where $P$ is pressure, $P_{\text{loss}}$ is pressure loss due to flow, and $R$ is flow resistance. This enables continuous analog computation with low power consumption.

\subsection{Dataflow Architecture (Arvind)}

Tagged token dataflow computing executes instructions when all input tokens are available, enabling natural parallelism. The execution model:
\begin{equation}
\text{Instruction executes when: } \forall \text{ input tokens } t_i: \text{available}(t_i)
\end{equation}
Token matching complexity is $O(t \log t)$ where $t$ is the number of tokens, enabling efficient fine-grained parallelism.

\subsection{ACE (Automatic Computing Engine) - Turing Architecture}

Based on Alan Turing's 1945 stored-program computer design, ACE uses unified memory for instructions and data:
\begin{equation}
\text{Memory}[PC] \rightarrow \text{Instruction} \rightarrow \text{Execute} \rightarrow PC++
\end{equation}
This historical architecture provides deterministic sequential execution, foundational to modern computing.

\subsection{Systolic Array Architecture}

Regular arrays of processing elements with local communication enable pipelined computation:
\begin{equation}
PE_{i,j}^{t+1} = f(PE_{i,j}^t, PE_{i-1,j}^t, PE_{i,j-1}^t)
\end{equation}
Data flows through the array in systolic (pulsing) patterns, achieving high throughput through pipelining.

\subsection{TPU (Tensor Processing Unit) - Patterson Architecture}

Google's TPU architecture specializes in matrix multiplication with a 128×128 matrix unit:
\begin{equation}
C = A \times B \text{ in } O(1) \text{ cycles for } 128 \times 128 \text{ matrices}
\end{equation}
The unified buffer (24 MB) and high memory bandwidth (900 GB/s) enable 92 TOPS throughput.

\subsection{Standard Parallel Computing Architectures}

\textbf{MPI (Message Passing Interface):} Distributed memory parallel computing for multi-node clusters, scalable to thousands of nodes with collective operations support.

\textbf{OpenMP (Open Multi-Processing):} Shared memory parallel computing with automatic load balancing, simple parallel programming model, and portable across platforms.

\textbf{Pthreads (POSIX Threads):} Fine-grained thread management with work-stealing support, low-level control for shared memory parallelism.

\subsection{GPU Computing}

\textbf{GPGPU (General-Purpose GPU):} Platform-agnostic GPU abstraction supporting multiple GPU vendors, high memory bandwidth, and massively parallel execution.

\subsection{Vector Processors}

\textbf{Vector Processor:} SIMD vector processing units for data-parallel operations, high throughput for vectorizable code with modern CPU support (AVX, NEON).

\subsection{Specialized Hardware}

\textbf{ASIC (Application-Specific Integrated Circuit):} Custom hardware optimized for ODE solving with highest performance, low power consumption, and custom instruction support.

\textbf{FPGA (Field-Programmable Gate Array):} Reconfigurable hardware with high parallelism, DSP slices for arithmetic, and customizable data paths.

\textbf{FPGA AWS F1 (Xilinx UltraScale+):} Cloud-based FPGA access with Xilinx UltraScale+ architecture, High-Level Synthesis support, and PCIe connectivity.

\textbf{DSP (Digital Signal Processor):} Specialized signal processing optimized for multiply-accumulate operations, low latency, and VLIW instruction parallelism.

\subsection{Quantum Processing Units}

\textbf{QPU Azure (Microsoft Quantum):} Microsoft Azure Quantum QPU for quantum-enhanced ODE solving with hybrid classical-quantum algorithms, error correction support, and cloud access.

\textbf{QPU Intel Horse Ridge:} Intel's cryogenic quantum control chip with multi-qubit gate support, adaptive control algorithms, and commercial quantum computing.

\subsection{Specialized Processing Units}

\textbf{TilePU Mellanox (Tile-GX72):} Mellanox many-core processor with 72 tiles, high memory bandwidth, efficient tile interconnect, and network processing optimization.

\textbf{TilePU Sunway (SW26010):} Sunway SW26010 many-core processor with 256 cores per chip (4 groups × 64 cores), register file communication, DMA support, used in Sunway TaihuLight supercomputer.

\textbf{DPU Microsoft:} Microsoft's Data Processing Unit for biological computation and data processing with specialized biological computation models.

\textbf{MFPU (Microfluidic Processing Unit):} Microfluidic circuits for computation using fluid dynamics, ultra-low power, continuous analog computation, and natural parallelism through channels.

\textbf{NPU (Neuromorphic Processing Unit):} General neuromorphic processing unit with event-driven computation, ultra-low power, adaptive learning, and brain-inspired architecture.

\textbf{LPU Lightmatter:} Lightmatter's photonic processing unit using light for computation, light-speed computation, low latency optical interconnect, and hybrid electro-optical processing.

\textbf{AsAP (Asynchronous Array of Simple Processors):} UC Davis architecture for fine-grained parallelism with asynchronous operation (no global clock), dynamic task scheduling, and flexible network topologies.

\textbf{Coprocessor Intel Xeon Phi:} Intel Xeon Phi many-core coprocessor with up to 72 cores, 512-bit wide vector units, high-bandwidth memory (HBM), and offload model for acceleration.

\subsection{GPU Architectures}

We support multiple GPU architectures:

\textbf{CUDA (NVIDIA):} 2560 cores, 900 GB/s bandwidth, tensor cores for mixed precision.

\textbf{Metal (Apple):} Optimized for Apple Silicon, unified memory architecture, 400 GB/s bandwidth.

\textbf{Vulkan (Cross-platform):} Low-overhead explicit API, supports NVIDIA/AMD/Intel, 600 GB/s bandwidth.

\textbf{AMD/ATI:} Wide SIMD (64 lanes), HBM memory (1 TB/s), wavefront-based execution.

\subsection{Spiralizer with Chord Algorithm (Chandra, Shyamal)}

The Spiralizer architecture combines Chord distributed hash tables with Robert Morris collision hashing (MIT) and spiral traversal:
\begin{equation}
\text{Hash}(k) = (k + i^2) \bmod m \text{ for collision attempt } i
\end{equation}
Chord finger tables enable O(\log n) lookup complexity, while spiral traversal provides efficient state space exploration.

\subsection{Lattice Architecture (Waterfront variation - Chandra, Shyamal)}

Variation of Turing's Waterfront architecture, presented by USC alum from HP Labs at MIT event online at Strata. Multi-dimensional lattice with Waterfront buffering:
\begin{equation}
\text{Buffer}[i] = \text{Buffer}[i] \cdot 0.5 + \text{Input}[i] \cdot 0.5
\end{equation}
Lattice routing achieves O(d) complexity for d dimensions with minimal hop count.

\subsection{Massively-Threaded Architecture (Korf)}

Richard Korf's frontier search with massive threading (1024+ threads), work-stealing queues, and tail recursion optimization enables O(n/p) complexity with p threads.

\subsection{Neuromorphic Architectures}

\textbf{TrueNorth (IBM):} 1 million neurons (4096 cores × 256 neurons), 26 pJ per spike, spike-timing dependent plasticity.

\textbf{Loihi (Intel):} Adaptive thresholds, structural plasticity, on-chip learning with configurable learning rates.

\textbf{BrainChips:} Event-driven computation, sparse representation, 100K neurons, 1 pJ per event.

\subsection{Memory Architectures}

\textbf{Racetrack (Parkin):} Magnetic domain wall memory with 3D stacking, low power non-volatile storage.

\textbf{Phase Change Memory (IBM):} Amorphous/crystalline phase transitions, SET (1 kOhm) / RESET (1 MOhm) resistance states, 100 ns programming time.

\subsection{Probabilistic Architectures}

\textbf{Lyric (MIT):} 256 probabilistic units, 64 random bit generators, hardware-accelerated Bayesian inference, Markov chain Monte Carlo support.

\textbf{HW Bayesian Networks (Chandra):} Hardware-accelerated inference engine, parallel inference on 256 nodes, approximate inference support.

\subsection{Search Algorithms}

\textbf{Semantic Lexographic Binary Search (Chandra \& Chandra):} Massively-threaded (512 threads) with tail recursion, semantic caching, lexographic ordering.

\textbf{Kernelized SPS Binary Search (Chandra, Shyamal):} Three kernel functions (Semantic, Pragmatic, Syntactic), kernel caching, 128×128×128 kernel space.

\subsection{Multiple-Search Representation Tree Algorithm}

The Multiple-Search Representation Tree algorithm uses multiple search strategies (BFS, DFS, A*, Best-First) with different state representations (vector, tree, graph) for solving ODEs. The algorithm builds a search tree where each node represents a state at a specific time, and explores the state space using parallel search strategies:

\begin{equation}
f(n) = g(n) + h(n)
\end{equation}

where $g(n)$ is the cost to reach node $n$ and $h(n)$ is the heuristic estimate. The algorithm maintains separate queues/stacks for each search strategy and selects the best solution from all strategies.

\section{Results Summary}

Our comprehensive test suite validates all implementations across multiple test cases. The exponential decay test demonstrates exceptional accuracy (99.99999\%) for all methods, while the harmonic oscillator test shows excellent performance (99.3-99.7\%) over a full period.

The framework now includes:
\begin{itemize}
\item Standard methods (RK3, DDRK3, AM, DDAM)
\item Parallel methods (Parallel RK3, Parallel AM, Stacked RK3)
\item Real-time and online methods (Real-Time RK3, Online RK3, Dynamic RK3)
\item Nonlinear programming solvers (Nonlinear ODE, Nonlinear PDE)
\item Karmarkar's Algorithm for polynomial-time linear programming
\item Interior Point Methods for non-convex, nonlinear, and online algorithms
\item Map/Reduce framework for distributed ODE solving on commodity hardware
\item Apache Spark framework with RDD-based fault tolerance and caching
\item Micro-Gas Jet circuit architecture for low-power analog computation
\item Dataflow architecture (Arvind) for fine-grained parallelism
\item ACE (Turing) architecture for historical stored-program computation
\item Systolic array architecture for pipelined matrix operations
\item TPU (Patterson) architecture for specialized matrix acceleration
\item GPU architectures: CUDA, Metal, Vulkan, AMD for massively parallel computation
\item Standard parallel computing: MPI (Message Passing Interface), OpenMP (Open Multi-Processing), Pthreads (POSIX Threads)
\item GPGPU (General-Purpose GPU) for platform-agnostic GPU computing
\item Vector Processor architecture for SIMD data-parallel operations
\item Specialized hardware: ASIC (Application-Specific Integrated Circuit), FPGA (Field-Programmable Gate Array), FPGA AWS F1 (Xilinx UltraScale+), DSP (Digital Signal Processor)
\item Quantum Processing Units: QPU Azure (Microsoft Quantum), QPU Intel Horse Ridge (cryogenic quantum control)
\item Specialized Processing Units: TilePU Mellanox (Tile-GX72), TilePU Sunway (SW26010), DPU Microsoft (biological computation), MFPU (Microfluidic Processing Unit), NPU (Neuromorphic Processing Unit), LPU Lightmatter (photonic computing)
\item AsAP (Asynchronous Array of Simple Processors) - UC Davis architecture
\item Coprocessor: Intel Xeon Phi many-core coprocessor with wide vector units
\item Spiralizer with Chord Algorithm (Chandra, Shyamal) using Robert Morris hashing
\item Lattice Architecture (Waterfront variation - Chandra, Shyamal)
\item Directed Diffusion with Manhattan Distance (Chandra, Shyamal) - flood fill focusing on statics rather than dynamics, inspired by Estrin and Govindan et al.
\item Massively-Threaded/Frontier Threaded (Korf) architecture
\item STARR architecture (Chandra et al.) - https://github.com/shyamalschandra/STARR
\item Neuromorphic architectures: TrueNorth (IBM), Loihi (Intel), BrainChips
\item Memory architectures: Racetrack (Parkin), Phase Change Memory (IBM)
\item Probabilistic architectures: Lyric (MIT), HW Bayesian Networks (Chandra)
\item Search algorithms: Semantic Lexographic BS, Kernelized SPS BS (Chandra, Shyamal)
\item Multiple-Search Representation Tree Algorithm (BFS, DFS, A*, Best-First with tree/graph representations)
\item Distributed solvers (Distributed Data-Driven, Distributed Online, Distributed Real-Time)
\item Cellular automata solvers (CA ODE, CA PDE)
\item Petri net solvers (Petri Net ODE, Petri Net PDE)
\item Multinomial Multi-Bit-Flipping MCMC for discrete optimization
\end{itemize}

\section{Conclusion}

We have presented a comprehensive framework for solving nonlinear ODEs using traditional and data-driven hierarchical methods, suitable for deployment on Apple platforms.

\bibliographystyle{plain}
\begin{thebibliography}{13}
\bibitem{rk3}
Butcher, J. C. (2008). \textit{Numerical Methods for Ordinary Differential Equations}. Wiley.

\bibitem{adams}
Gear, C. W. (1971). \textit{Numerical Initial Value Problems in Ordinary Differential Equations}. Prentice-Hall.

\bibitem{mapreduce}
Dean, J., \& Ghemawat, S. (2008). MapReduce: Simplified Data Processing on Large Clusters. \textit{Communications of the ACM}, 51(1), 107-113.

\bibitem{spark}
Zaharia, M., et al. (2012). Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing. \textit{NSDI}, 15-28.

\bibitem{karmarkar}
Karmarkar, N. (1984). A new polynomial-time algorithm for linear programming. \textit{Combinatorica}, 4(4), 373-395.

\bibitem{chord}
Stoica, I., Morris, R., Karger, D., Kaashoek, M. F., \& Balakrishnan, H. (2001). Chord: A Scalable Peer-to-peer Lookup Service for Internet Applications. \textit{ACM SIGCOMM Computer Communication Review}, 31(4), 149-160. DOI: 10.1145/964723.383071. Available at: \url{https://en.wikipedia.org/wiki/Chord_(peer-to-peer)}

\bibitem{directed_diffusion}
Estrin, D., Govindan, R., Heidemann, J., \& Kumar, S. (1999). Next Century Challenges: Scalable Coordination in Sensor Networks. \textit{Proceedings of the 5th Annual ACM/IEEE International Conference on Mobile Computing and Networking (MobiCom)}, 263-270. DOI: 10.1145/313451.313556

\bibitem{ieee_7229264}
IEEE Xplore Document 7229264. Available at: \url{https://ieeexplore.ieee.org/abstract/document/7229264}

\bibitem{ieee_8259423}
IEEE Xplore Document 8259423. Available at: \url{https://ieeexplore.ieee.org/abstract/document/8259423}

\bibitem{racetrack_wikipedia}
Racetrack Memory. Wikipedia. Available at: \url{https://en.wikipedia.org/wiki/Racetrack_memory}
\end{thebibliography}

\end{document}
